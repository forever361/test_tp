


1.活动名称：
“产品优化大挑战，赢取奖品”

2.活动目的：
通过用户反馈产品的使用建议或Bug，帮助产品优化，同时提升自己的使用体验。

3.活动时间：
2024年10月1日 - 2024年12月31日

4.参与对象：
CDP员工

5.活动形式：
用户通过填写表单或提交反馈的方式，提供对产品的改进建议或Bug报告。通过评选机制，前10名有效的反馈者将获得奖励。


Event Name:
"Product Optimization Challenge: Win Prizes"

Event Objective:
Encourage users to provide product improvement suggestions or bug reports to help optimize the product and enhance your own user experience.

Event Duration:
October 1, 2024 - December 31, 2024

Participants:
CDP employees

Event Format:
Participants can submit feedback through forms or reports, offering product improvement suggestions or bug reports. The top 10 most valuable feedback submissions will be rewarded based on an evaluation system.

1. Requirements Analysis

    Goal Setting: Define the project goals and functional requirements, such as displaying time data for different phases and calculating the total time versus the expected time.
    Data Sources: Identify the sources of data, including extracting time from server log files and retrieving phase data from the database.

2. System Design

    Architecture Design:
        Frontend: Design the user interface (UI) to display time data for different phases using HTML/CSS and JavaScript.
        Backend: Design API endpoints to fetch data, handle log file processing, and perform database queries.

    Database Design:
        Table Structure: Design the database schema to store time data for different phases, such as the datatest.datatest table.

3. Implementation Process

    Backend Implementation:
        Log File Processing:
            Connect to the file server and access log files via SSH.
            Parse the time data from the log files to extract the earliest start_time and latest end_time.
        Database Queries:
            Connect to the PostgreSQL database and query the table for time data.
            Use SQL queries to retrieve data and format datetime objects as strings.

    Frontend Implementation:
        AJAX Requests: Use AJAX to send requests to the backend API and fetch data.
        Data Processing:
            Parse the JSON response and format time data into the desired date format.
            Calculate time differences and update UI elements accordingly.
        UI Updates:
            Display the processed data on the webpage, including start times, end times, and time differences for different phases.
            Show success or failure messages based on the comparison between total time and expected time.

1. 需求分析

    目标设定：明确项目的目标和功能需求，例如展示不同阶段的时间数据，并计算总时间与预期时间的对比。
    数据来源：确定数据来源，包括从服务器日志文件提取时间、从数据库获取阶段数据等。

2. 系统设计

    架构设计：
        前端：设计用户界面（UI）来显示不同阶段的时间数据，使用 HTML/CSS 和 JavaScript。
        后端：设计 API 接口来获取数据，处理日志文件和数据库查询。

    数据库设计：
        表结构：设计数据库表结构来存储不同阶段的时间数据，例如 datatest.datatest 表。

3. 实现过程

    后端实现：
        日志文件处理：
            连接到文件服务器，通过 SSH 访问日志文件。
            解析日志文件中的时间数据，提取最早的 start_time 和最晚的 end_time。
        数据库查询：
            连接到 PostgreSQL 数据库，查询表中的时间数据。
            使用 SQL 查询语句获取数据，并将 datetime 对象格式化为字符串。

    前端实现：
        AJAX 请求：使用 AJAX 向后端 API 发送请求，获取数据。
        数据处理：
            解析 JSON 响应，将时间数据格式化为所需的日期格式。
            计算时间差，并更新 UI 元素的内容。
        UI 更新：
            将处理后的数据展示在页面上，包括不同阶段的开始时间、结束时间和时间差。
            根据总时间与预期时间的对比，显示成功或失败的消息


CREATE TABLE IF NOT EXISTS tanos.admin_config
(
    login_type character varying COLLATE pg_catalog."default"
)


Function Design:

1.Create a New Team:

Provide UI for admin to create new teams.
Input the team name and information, then save it to the database.

2.Configure Access Permissions:

Provide UI for admin to define different permission settings.
Different permission levels can be set, with corresponding permissions defined for each level.

3.Member Management:

Provide an interface for team owners or admin to invite new members to join the team.
Members can be removed or leave the team.

-- 创建用户团队关联表
CREATE TABLE xcheck.user_teams (
  userid INT NOT NULL,
  teamid INT NOT NULL,
  is_owner INT NOT NULL DEFAULT 0,
  FOREIGN KEY (userid) REFERENCES xcheck."user" (user_id),
  FOREIGN KEY (teamid) REFERENCES xcheck.team (team_id),
  PRIMARY KEY (userid, teamid)
);



-- Table: xcheck.role2

-- DROP TABLE IF EXISTS xcheck.role2;

CREATE TABLE IF NOT EXISTS xcheck.role2
(
    role_id integer NOT NULL,
    name character(100) COLLATE pg_catalog."default",
    read character(5) COLLATE pg_catalog."default",
    write character(5) COLLATE pg_catalog."default",
    role_value character(300) COLLATE pg_catalog."default",
    CONSTRAINT role2_pkey PRIMARY KEY (role_id)
)

TABLESPACE pg_default;

ALTER TABLE IF EXISTS xcheck.role2
    OWNER to postgres;


3002	DelosUsers                                                                                          	0	1	00001000011
3001	Guest                                                                                               	1	0	00000000010
3000	Admin                                                                                               	0	1	11111111111
3003	ChinaDataSolution                                                                                   	0	1	11100000011

11|11|11|11|11|11|11|11|11|11|11
00|00|00|00|00|00|00|00|00|10|00
00|00|00|00|11|00|00|00|00|11|11
11|11|11|00|00|00|00|00|00|11|11


-----

import os
import oss2

def create_local_directories(remote_path, local_root):
    remote_directories = remote_path.split('/')
    local_path = local_root

    for i, directory in enumerate(remote_directories):
        local_path = os.path.join(local_path, directory)
        if i < len(remote_directories) - 1 and not os.path.exists(local_path):
            os.makedirs(local_path)

def download_oss_directory(oss_dir, sav_dir, access_key_id, access_key_secret, endpoint, bucket_name):
    auth = oss2.Auth(access_key_id, access_key_secret)
    bucket = oss2.Bucket(auth, endpoint, bucket_name)

    for obj in oss2.ObjectIterator(bucket, prefix=oss_dir):
        if obj.is_prefix():
            # 跳过目录
            continue

        remote_path = obj.key
        local_path = os.path.join(sav_dir, remote_path)

        create_local_directories(remote_path, sav_dir)

        # 下载文件
        bucket.get_object_to_file(remote_path, local_path)
        print(f'Downloaded: {local_path}')

if __name__ == '__main':
    # 远程OSS目录路径
    oss_dir = 'new/test/TANOS/50001/csv/'

    # 本地保存目录的根路径
    local_root = './'

    # 阿里云OSS配置
    access_key_id = 'your_access_key_id'
    access_key_secret = 'your_access_key_secret'
    endpoint = 'your_endpoint'
    bucket_name = 'your_bucket_name'

    download_oss_directory(oss_dir, local_root, access_key_id, access_key_secret, endpoint, bucket_name)



create sequence xcheck.target_id_seq increment by 1 minvalue 1 no maxvalue start with 1;
CREATE TABLE xcheck.config_target_info
(
    target_id integer NOT NULL DEFAULT nextval('xcheck.target_id_seq'::regclass),
    user_id integer NOT NULL,
    database_type character(50) COLLATE pg_catalog."default",
    target_access_id character(100) COLLATE pg_catalog."default",
    target_secret_access_key character(100) COLLATE pg_catalog."default",
    target_project character(100) COLLATE pg_catalog."default",
    target_endpoint character(100) COLLATE pg_catalog."default",
    create_date timestamp without time zone,
    CONSTRAINT config_target_info_pkey PRIMARY KEY (target_id)
)


create sequence xcheck.api_suite_id_seq increment by 1 minvalue 1 no maxvalue start with 10000;
CREATE TABLE xcheck.api_batch_suite
(
    suite_id character varying NOT NULL DEFAULT nextval('xcheck.api_suite_id_seq'::regclass),
    user_id character varying,
    suite_name character varying,
    create_date timestamp without time zone
)


create sequence xcheck.api_job_id_seq increment by 1 minvalue 1 no maxvalue start with 10000;
CREATE TABLE xcheck.api_batch_job
(
    job_id character varying NOT NULL DEFAULT nextval('xcheck.api_job_id_seq'::regclass),
    user_id character varying,
    job_name character varying,
    create_date timestamp without time zone
)

create sequence xcheck.api_result_id_seq increment by 1 minvalue 1 no maxvalue start with 1;
CREATE TABLE xcheck.api_batch_result
(
    api_result_id character varying COLLATE pg_catalog."default" NOT NULL DEFAULT nextval('xcheck.api_result_id_seq'::regclass),
    job_id character varying COLLATE pg_catalog."default",
	case_id racter varying COLLATE pg_catalog."default",
    user_id character varying COLLATE pg_catalog."default",
    url character varying COLLATE pg_catalog."default",
    methods character varying COLLATE pg_catalog."default",
    request_body character varying COLLATE pg_catalog."default",
    headers character varying COLLATE pg_catalog."default",
    expected_result character varying COLLATE pg_catalog."default",
    test_result character varying COLLATE pg_catalog."default",
    create_date timestamp without time zone
)

create sequence xcheck.api_case_id_seq increment by 1 minvalue 1 no maxvalue start with 10000;
CREATE TABLE xcheck.api_batch_case
(
    case_id character varying COLLATE pg_catalog."default" NOT NULL DEFAULT nextval('xcheck.api_case_id_seq'::regclass),
    suite_id character varying COLLATE pg_catalog."default",
    user_id character varying COLLATE pg_catalog."default",
    url character varying COLLATE pg_catalog."default",
    methods character varying COLLATE pg_catalog."default",
    request_body character varying COLLATE pg_catalog."default",
    headers character varying COLLATE pg_catalog."default",
    expected_result character varying COLLATE pg_catalog."default",
    create_date timestamp without time zone
)


CREATE TABLE xcheck.api_batch_token
(
    job_id character varying COLLATE pg_catalog."default",
    url character varying COLLATE pg_catalog."default",
    body character varying COLLATE pg_catalog."default",
	test_rule character varying COLLATE pg_catalog."default",
    create_date timestamp without time zone
)




CREATE TABLE IF NOT EXISTS tanos.data_batch_test_case
(
    case_id integer NOT NULL DEFAULT nextval('tanos.generator_room_id'::regclass),
    case_name character(100) COLLATE pg_catalog."default",
    user_id integer,
    create_date timestamp without time zone,
    CONSTRAINT test_case_pkey4 PRIMARY KEY (case_id)
)

test

settings:
  env:
    BASE_DIR: /home/taurus/taurus_container_scripts  # 脚本目录
  artifacts-dir: /home/taurus/taurus_container_artifacts/simple1/%Y-%m-%d_%H-%M  # path where to save artifacts, default is %Y-%m-%d_%H-%M-%S.%f

scenarios:
  my_scenario:
    requests:
- label: Home
        url: /       #路径
        method: GET  #请求方式

execution:
- concurrency: 10#并发线程数
  ramp-up: 1m# 启动时间
  hold-for: 2m30s# 持续时间
  scenario:        # 测试场景
default-address: http://www.example.com/  # 请求地址
    requests:
- include-scenario: my_scenario  # 场景名称

reporting:
- module: final-stats # 摘要报告
- module: console     # 控制台

modules:
    jmeter:
        version: 5.2.1# 版本号